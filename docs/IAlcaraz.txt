 Bueno, bienvenidos a una tercera edición de charlas chi. En esta oportunidad tenemos el placer de tenerlo a Franco. Voy a hacer una breve presentación, como lo decía en el mail de invitación. Franco se define como un músico y dibujante que se dedica a la ingeniería. Le gusta presentarse así. Nacido en Tucumán, se recibió en 2007 de ingeniería electrónica en la UNT, que es la Universidad Nacional de Tucumán. Y continuó sus estudios con una maestría en ingeniería en el IB, orientada a inteligencia artificial, que es el tema que nos convoca. En INVAP trabajó en el grupo de radiofrecuencias y luego en el de técnicas digitales. Participó en proyectos satelitales y de radares y también fue profesor en la Universidad Nacional de Río Negro. Se volcó a la inteligencia artificial hace más de seis años y actualmente dirige los desarrollos relacionados con ese área en la gerencia de gobierno de INVAP. Y es uno de los expertos que representa Argentina en el Global Partnership on Artificial Intelligence. Así que bueno, ahí tenemos acá un experto en el tema. Estamos todos y todas muy ansiosos y ansiosas y expectantes con esta charla. La verdad que fue muy buena la convocatoria. Así que bueno, te doy todo el espacio, Franco, para que comiences y bueno, entrarnos en esta temática tan interesante y atractiva. Bueno, gracias Dani y gracias a todos por sumarse a la charla. Brindar un poquito de su tiempo para charlar de algunas cosas interesantes como la inteligencia artificial. Esperen que comparto. ¿Se ve ahí ya? Sí, Dani. Dice Franco. Bueno, arranco entonces. La idea, bueno, me acercaron la propuesta de hacer una charlita sobre inteligencia artificial. Ahí estuvimos debatiendo un poquito la temática y decidimos ir por algo un poco más del lado de divulgación. Y yo le voy a aportar un tinte un poquito más reflexivo, más sobre el final. Veamos así que los voy a invitar un poco también a sumarse a esas reflexiones. Capaz que se da lo inverso de que yo les deje más preguntas a ustedes que a ustedes a mí. Pero bueno, nada, creo que hoy es un tema que está bien caliente, lo de inteligencia artificial. Así que bueno, imagino que también por eso la convocatoria. Así que desde ya les agradezco un montón. Bueno, sin más preámbulos voy a arrancar porque me quedo un poquito largo así que también voy a ir un poquito rápido. Bueno, la idea entonces la voy a dividir en dos a la charla. La primera va a ser hablar sobre inteligencia un poquito en general, inteligencia, inteligencia artificial. Y luego la segunda parte va a tratar del impacto de esta tecnología que está atravesando a todos en distintos ámbitos. Elegí un poquito la analogía de arrancar con los cuervos, por el dicho que si criamos cuervos nos terminarán sacando los ojos. Bueno, si realmente la inteligencia artificial vendría a representar la figura del cuervo no y si nos va a terminar sacando los ojos. Bueno, nada, como para arrancar la charla y hablar un poquito de este bicho interesante es considerada en gran parte por creo la comunidad científica como la ave más inteligente. Pero lo sorprendente de este animal es todo lo que puede hacer con ese cerebrito tan chico de alguna forma. Puede resolver problemas, problemas complejos, problemas que involucran lógica, manejo de secuencias, de herramientas y demás. Bueno, construye sus herramientas, se puede comunicar con sonidos, imita sonidos de animales o nuestros inclusive. Se comunica también por lenguaje corporal. Construye comunidades muy complejas con distintos niveles jerárquicos sociales. Tiene buena memoria, le gusta jugar y se adapta muy bien a distintos entornos. Así que de alguna forma, salvando las diferencias, se parecen en gran parte a nosotros también. Bueno, sobre la inteligencia. La inteligencia en definitiva si uno la quiere definir o busca definiciones hay muchísimas. Depende muchísimo el ámbito o para qué uno quiere aplicar una definición de inteligencia. Pero bueno, cuando nos metemos en el plano de definir, al menos en este caso la inteligencia, entramos en un plano medio gris. Pero bueno, había que traer una definición de inteligencia. Así que bueno, en la búsqueda fui pasando por varias, pero hay una que más o menos me deja contento. Sin embargo, hay que tomar con pinzas. Con pinzas qué es la inteligencia y a quiénes nosotros consideramos inteligente y a quiénes no. En definitiva. Bueno, la definición es esta. Permítame que la lea. Capacidad de percibir o inferir información y retenerla como conocimiento para aplicarlo a comportamientos adaptativos entre un entorno o contexto. O sea, básicamente es adquirir información de nuestro entorno, almacenarla o almacenar lo que creamos conveniente. Y en función de esa información actual y de toda la que recopilamos antes en nuestra historia de vida. Decidir cómo comportarnos ante esa situación y esas acciones obviamente van a influir en nuestro entorno. Y ahí se forma un ciclo que es en el que esas acciones inclusive modifican el entorno trayéndonos más información. O sea, por nosotros mismos o por otros agentes inteligentes dentro de ese entorno. Entonces vemos que la inteligencia entonces no es sólo la definición, sino que también se le adozan algunas capacidades de las de los que consideramos entes inteligentes. Que son un poco las que están listadas ahí. Ellas estarán más o menos... Tendrán una idea de lo que es cada una de ellas. No vamos a entrar en detalles. Y yo resalté dos ahí, que es el aprendizaje y la resolución de problemas. ¿Por qué está resaltado? Porque básicamente esas son las fortalezas de la inteligencia artificial. Donde las otras que no están resaltadas hoy por hoy no se muestra que haya al menos una capacidad fuerte desde el lado del inteligencio artificial en esos aspectos. Pero se van logrando avances. Más allá de las capacidades también hay una multiplicidad de inteligencia. Esto de las inteligencias múltiples, de que no sólo la inteligencia lógico-matemática que es medida por el IQ, digamos, el coeficiente intelectual y demás es la única que interesa. Y acá yo rescato de que quizás aparecen estas múltiples inteligencias también con un dominio desde el lado de la inteligencia artificial en las que están resaltadas ahí. Ya sea por el lado de la robótica, por el lado del procesamiento de información como de videos, imágenes, de sonidos. Y algunas que están hacia el final en las cuales se han logrado avances significativos en el último año o dos años. En donde se manifiesta algún rasgo creativo, por ejemplo, o colaborativo entre agentes inteligentes construido de manera artificial. Así que bueno, parece que somos multi inteligentes. Ya no nos ha alcanzado a conocer sólo inteligentes, así que somos múltiples de inteligentes. Bueno, hay un club entonces, el club de los inteligentes. El problema es que el club de los inteligentes yo al menos no le encuentro el borde, digamos. No sé a quién descartar en la frontera de ser o no ser inteligente. O sea, ¿es un borde difuso? ¿Ya no era difícil definir inteligencia? Me parece que es más difícil también pretender establecer un borde bien definido de quién es o quién no es inteligente. Bueno, ahí están algunos de los animales que nosotros al menos consideramos inteligentes. Pero inclusive dentro de nosotros mismos, dentro de nuestra especie también buscamos a veces poner esa distinción. Así que bueno, ahí es un plano polémico, si se quiere. Pero bueno, está. Y más que nada tiene que ver más con una cuestión de percepción que con una cuestión de medida. Entonces la pregunta acá sería, ¿en qué nivel entra la inteligencia artificial al menos en el estado del arte en el que se encuentra? Bueno, inteligencia artificial. A ver. La inteligencia artificial la estamos creando. Ya es un campo que se viene desarrollando hace mucho tiempo con sus vaivenes. Se ha estancado también a lo largo del tiempo. Ya llevará como unos 60 años de desarrollo. Pero es cierto que en la última década, últimos 15 años es donde hemos visto los grandes avances. Después vamos a hablar un poco por qué se ha dado así. Pero bueno, estamos creando esto. No sabemos bien para qué o por qué. Pero bueno, me parece que está mucho en nuestra naturaleza el seguir avanzando y creando cosas nuevas. En este caso, la tecnología que nos convoca es la inteligencia artificial. De nuevo en el plano de definiciones, no hay una definición cerrada para la inteligencia artificial. Así que yo rescaté esta de Kaplan y Heilen, que son dos profesionales que trabajan más en el ámbito de la innovación y marketing y demás. Que me pareció la más adecuada. Pero si ustedes la leen y la releen, van a ver que esta definición también aplica a nosotros de alguna forma. Porque seguimos siendo un sistema, un sistema multicellular en este caso. Y los datos ahí resaltados, sigue siendo información. O sea que hay prácticamente una correlación fuerte entre esta definición y la definición de inteligencia general. Entonces, pareciera ser que lo único que le otorga el rasgo de artificial es el hecho de que no esté vivo. Y no me quiero meter en ese debate, digamos. De que cuando o no empezaremos a considerar como algo vivo a la inteligencia artificial. Ya hubo algunas noticias vinculadas a alguna inteligencia artificial de Google. Además, no sé si hayan estado tanto. Si después le interesa, se las comento un poquito más. Bueno. Acá no voy a hacer una pasada por todas estas. Pero en esta diapositiva quise resumir un poco las aplicaciones más fuertes, atravesadas o basadas en la tecnología de inteligencia artificial. Ya estarán al tanto muchos de ustedes en esto. Porque básicamente se nos ha metido en la cotidienedad. Todas estas aplicaciones, y algunas que inclusive no sabemos que también por detrás se basan en inteligencia artificial, están basadas en tecnologías dentro de la inteligencia artificial. Como el procesamiento o la generación de lenguaje natural. Como la clasificación o generación de audio, imágenes y videos. Y algunas más. No quería dejar de mencionar, no me quiero meter mucho en el plano técnico, pero no me quería privar de contarles qué es el machine learning. Porque hablamos mucho de machine learning, y a veces lo usamos como sinónimo de inteligencia artificial, pero no. El machine learning es una rama de la inteligencia artificial, o aprendizaje automático, sería la traducción, que básicamente es enseñarles a las máquinas. Entonces uno dirá, pero eso es la inteligencia artificial. No, la inteligencia artificial es un poco más amplio, pero hoy por hoy todos los grandes desarrollos que se dan en el ámbito de inteligencia artificial vienen de este lado, de este barrio de la inteligencia artificial. Básicamente, solo para ponernos un poco a tono con el vocabulario, el diagramita que está abajo muestra un poco algunos conceptos que se usan cotidianamente para hablar de inteligencia artificial, que son los modelos de inteligencia artificial, que es el rectángulo ese que ven en el centro, que es básicamente el agente inteligente. El agente al que entrenaremos y el agente que luego, una vez entrenado, nos servirá para darnos información o procesar información de manera inteligente. Ese modelo de inteligencia artificial básicamente toma información que nosotros le proveemos o que adquiere del entorno, la procesa mediante una algoritmia y nos entrega resultados, que son las inferencias. Ahora, todo ese proceso se entrena usando muchísimos datos, múltiples datos, que en general se los denomina dataset. Acá me gustaría ensayar y contarles algunos paralelismos, que yo al menos encuentro entre la inteligencia convencional y la inteligencia artificial. Básicamente, ¿qué nos define como seres inteligentes? En definitiva, es nuestra materia gris, nuestra corteza cerebral, que obviamente está presente en múltiples animales. Los mamíferos todos presentan esta distribución de nebronas de una manera particular. En este caso y en nuestro caso, no vamos a enfocar básicamente en lo que es la materia gris, que es esa cobertura del cerebro, no los niveles más inferiores o más primitivos del cerebro, en donde hay una gran densidad de conexiones neuronales o interconexiones neuronales, y que básicamente es el tejido responsable de la percepción, de la imaginación, pensamiento, del juicio, decisión, etcétera. Por lo cual, es este tejido el que nos permite a nosotros manifestar inteligencia. Bueno, la base de procesamiento de ese tejido, o la unidad de cómputo, si se quiere, de ese tejido es la neurona, nuestras neuronas, por si lo así. Así que esa célula básicamente tiene como tres grandes partes, en donde la parte afuera del cuerpo de la neurona, que son las dendritas, son las que van a captar información de otras neuronas, la van a integrar en esa información, la van a procesar en su cuerpo, todo a través de señales químicas, y luego van a transmitir ese resultado hacia otras neuronas. En definitiva o no, después eso se puede conectar con otras células y demás. Y ahí es donde se produce ese contacto, esa transmisión de información entre neuronas, del cual vamos a llamar sinapsis. La foto esa que muestro ahí es de una neurona que es del tipo piramidal, que es la que mayormente se encuentra en nuestra corteza cerebral, y puede presentar múltiples conexiones, del orden de los miles de conexiones entre neuronas. Bueno, ese era el reino animal. Y en el reino digital me voy a quedar con la neurona o el equivalente a neurona que va a conformar las redes neuronales que luego implementan gran parte de los algoritmos de inteligencia artificial hoy en boga. Hay otro estilo, no todos se basan en esto, pero bueno, en definitiva fíjense las similitudes. Tenemos entradas que equivaldrían a las dendritas, los pesos, que son básicamente cuán fuertes son esas conexiones neuronales entre una u otra, estos pesos o parámetros después van a ser importantes las filminas que siguen. Luego toda esa información, eso es como una multiplicación de señales. Luego se combinan, se suman, se le aplica algún bias, un offset, y se manda a una función de activación que se llama. Eso también tiene su equivalencia en las neuronas fisiológicas. Y estas funciones suelen ser no lineales, bueno, pasa por esa función y nos entra en un resultado. El porqué de la no linealidad lo dejamos para otra ocasión, es un poquito más técnico. Bueno, sigamos la comparación entonces. Si comparamos a nuestro querido Cuervo, tiene alrededor de 1200 millones de neuronas. Pero ese no es el parámetro en definitiva que nos interesa comparar, por ejemplo, con modelos como ChatGPT de inteligencia artificial el cual tiene 20 millones de parámetros y está basado en realidad en un modelo más complejo que es el GPD3, que tiene 175 millones de parámetros. Esos parámetros, esos pesos que veíamos antes en las neuronas, son los que se tendría que comparar, pero no contra la cantidad de neuronas, sino contra la cantidad de conexiones neuronales o la sinapsis. Si esto es solo un estimativo, el Cuervo podría tener alrededor de 1 a 12 billones de conexiones sinápticas. Con lo cual, ahí ChatGPT perdió un poquito, o todavía no alcanzó ese nivel. Sin embargo, el nuevo modelo lanzado por OpenAI, que es GPT-4, tiene alrededor de 1.8 billones de parámetros. Imagínense la escala de cómputo que ya se está logrando actualmente para estos modelos. Así que, bueno, equivalencia, sinapsis parámetro. ¿Qué pasa con nosotros? Bueno, nosotros estamos un poquito más alejados, todavía le estamos ganando un poquito a GPT. Estamos alrededor de 14 mil a 18 mil millones de neuronas, lo que equivale a más o menos 140 a 240 billones de conexiones sinápticas. Eso varía, digamos, dependiendo del tamaño del cerebro, hay unos rasgos asociados a sexo, por ejemplo, y demás. Ahí hay variaciones, pero básicamente ese es el rango. Y si lo comparamos contra otras especies, podemos ver el elefante con 7.800 millones, el orangután, que ya tenemos algunas similitudes un poco más fuertes, casi 10.000 millones, y el delfín que se nos acerca bastante con 12.000. Y dato de color, no sé si sabían, pero hay animales con más cantidad de neuronas que nosotros. Por ejemplo, la orca común tiene 43.000 millones. Así que imagínense si la orca tuviera manos y pies, lo que hubiera logrado hacer. Menos mal que nosotros logramos bajarnos de los árboles y la orca no salir del agua. Perdón, Franco, te puedo hacer una pregunta? ¿Por qué ahí empezás a comparar neuronas y recién estabas comparando sinapsis? Ok, buena pregunta. La información de la sinapsis no está disponible en general para los otros animales. Uno puede hacer un estimativo, un poco lo que dije de las neuronas piramidales, que tienen del orden de 10.000 a 10.000 conexiones, uno que podría multiplicar esto por 10 o por 10.000, por mil o por 10.000, perdón, en conexiones neuronales para travesadas sinápticas. Yo no encontré al menos los datos del estimativo de conexiones sinápticas para estos animales. Si hay un estudio de cuántas neuronas hay en el sistema nervioso completo versus lo que hay en el córtex. Pero no conseguí el dato exacto o al menos científico relevado de las conexiones sinápticas. Perdón, de acuerdo a la definición de inteligencia que estabas dando, no necesariamente la cantidad de neuronas es proporcional al nivel de inteligencia. Exactamente, la capacidad está más asociada a las conexiones sinápticas. Pero bueno, se supone que hay un orden de, como somos mamíferos, como compartimos una estructura cerebral parecida, hay un orden de magnitud, un factor que se mantendría. Sería equivalente comparar entre neuronas, entre nosotros, pero no entre un modelo de inteligencia artificial. Después, más allá de la capacidad neuronal, que sería en definitiva las conexiones sinápticas que tenemos, hay un aspecto importante acá que es la estructura. Porque está visto que la forma en que se arman esas redes neuronales influye y mucho en la capacidad de cómputo o de desarrollar determinadas tareas. Si recuerdan la figura del cerebro, se acuerdan que tiene como unos pliegues, esos pliegues que se ven por fuera, que se llaman circunvoluciones y surcos. Básicamente, lo que están permitiendo es extender la superficie de la corteza cerebral en un menor volumen para que entre en nuestro cráneo y poder tener así múltiples conexiones, muchas más conexiones neuronales. Pero a su vez eso también influye en la forma en que se conectan las neuronas y se comunican. Esto mismo también pasa en la inteligencia artificial. Esa red que ustedes ven ahí es lo que se llama una red densa. Cada uno de esos circulitos vendría a representar esta neurona del reino digital. Y este tipo de redes básicamente se conforman por capas o capas ocultas y hay una capa de entrada y una capa de salida. ¿Recuerdan el modelito que les mostré del gráfico ese diáorama? Básicamente la información entraría por la izquierda, sale por la derecha y cada una de esas líneas son multiplicaciones. Esto también existe en los cerebros, los mamíferos y demás, en múltiples zonas, estructuras equivalentes. Pero en inteligencia artificial, por ejemplo, se vio que construyendo otro tipo de redes neuronales, o sea, cambiando la estructura, cambiando la forma en que se conecta, se lograban mejores desempeños, incluso con menor cantidad de neuronas. ¿Va bien? Este es el caso de las redes convolucionales, en donde básicamente se usa un grupo de neuronas para explorar una zona de la imagen y en función de eso procesar. Y se vio que esos filtros, esos agrupadores de información, luego presentaban filtros similares a lo que se desarrollaban en la corteza visual primaria, de los mamíferos. Así que bueno, ahí también hay un paralelismo fuerte, porque evidentemente hemos evolucionado en la forma en que el cerebro se conecta desde cero, si se quiere, para poder facilitar el procesamiento de determinada información para realizar determinadas tareas. Bueno, y hace unos años, en el 2007 en realidad se presentó el primer paper, pero recién en los últimos años se ha hecho uso extensivo de una nueva estructura que se llama Transformers, no hace alusión a la película más allá de la imagen allá, pero esta estructura realmente ha venido a revolucionar gran parte de la inteligencia artificial del deep learning, de lo que se llama aprendizaje profundo, porque ha permitido conseguir tamaños enormes de redes neuronales que pueden procesar muchísima información y lograr el desempeño que están teniendo estos modelos como por ejemplo, ChatGPT, que está basado en este tipo de redes neuronales. Ahora, cada uno de esos bloquecitos que está ahí en realidad no son tan complejos, son operaciones matriciales, básicamente multiplicaciones y sumas combinadas con estas redes neuronales densas que les mostré antes. Pero bueno, esto ha resultado ser super eficiente para procesar gran volumen de información. Y por último, digamos, en esta línea, lo que les quería contar es que hay una rama fuerte, pero aún todavía muy verde dentro de la inteligencia artificial, que es la Inteligencia Artificial General, o AGI, en vez de CEI. Básicamente, lo que están buscando es conseguir modelos de inteligencia artificial que no se entrenen de la manera convencional, porque la manera convencional básicamente lo que están generando son lo que se llama una inteligencia artificial estrecha. Están muy optimizadas para un determinado tipo de tarea. Y es más, en muchas de esas tareas ya nos han superado al desempeño humano, digamos. Así que bueno, esta rama está muy activa en los últimos años, está logrando avances, pero bueno, todavía está ahí en pañales, digamos. Así que bueno, básicamente, un poco lo que está listado ahí, intentar tener un aprendizaje más parecido al que tienen los animales, si se quiere, de manera general. Bueno, no quería dejarlo de... Perdón, Franco, ahí estaban preguntando en el chat, como que, por ejemplo, ¿qué tareas? No, más que nada, digamos, por ejemplo, en resolución de problemas... Ah, pues no estoy viendo el chat. Bueno, se ponen. Bueno, coméntame vos, Dani, si aparece ahí alguna pregunta. Más que nada, de abordar la resolución de problemas de una manera más integral. Eso es un abordaje, por ejemplo, ¿no? De intentar combinar información o múltiples habilidades para hacer la resolución de un problema. Porque hoy los algoritmos de inteligencia artificial Narrow, los estrechos, digamos, se piensan exclusivamente para resolver, por ejemplo, proceso una imagen, identifínco dónde está el gatito. Entonces, lo que se quiere construir son modelos que aprendan, sin necesidad de especificarle una tarea puntual. Entonces, que logren conectar información, que logren conectar habilidades, ¿no? Tener un aprendizaje general, no tener que darles datos ya procesados para que aprenda esa tarea específica, sino que los pueda inferir. Y, bueno, y luego desarrollar habilidades más parecidas a las nuestras, como el razonamiento o el sentido común, ¿no? No sé si eso responde, igual la pregunta. Perdón, ¿puedo hacer una pregunta? Díganos. Cuando vos hablás y decís mejorar las habilidades de la inteligencia artificial para hacer inferencias. Yo entiendo que la inteligencia artificial siempre hace comparaciones contra información conocida y verifica si lo que está viendo es igual a la información conocida. ¿Cuál sería el modelo para que la inteligencia artificial observe objetos o situaciones desconocidas y pueda elaborar una definición observando esa información desconocida? Bueno, ese es precisamente el objetivo de este campo, ¿no? Ya se están logrando algunos modelos que muestran que se están, se están acercando un poco a eso. No está hoy, no está respondida esa pregunta. Igualmente quería mencionar una cosa. La inteligencia artificial va un poco más allá de conectar información, ¿no? O sea, hace inferencia y obtiene patrones que están atrás de la información en sí, de cómo se relaciona la información en múltiples ámbitos. O sea, no es simplemente buscar donde algo que yo le estoy proveyendo coincide algo con lo cual yo aprendí anteriormente como modelo inteligencia artificial, ¿no? Sino que puede encontrar similitudes o puede, por ejemplo, inferir cosas que ya vamos a hablar un poquito más adelante de, por ejemplo, los lenguajes, los grandes modelos para el lenguaje natural y demás cómo funcionan. Pero no es tan sencillo, digamos. Es más, hay muchos modelos de inteligencia artificial que son tan grandes, son tan complejos internamente que funcionan bien, pero nosotros no somos capaces de interpretar cómo lo están haciendo. O sea, sabemos las operaciones que hace, pero no entendemos cómo hace la relación entre distintas fuentes de información. En algunos sí, tenemos interpretabilidad, lo que se llama, pero en otros no. Bueno, sigo. Perdón, la última. ¿Y el modelo de estas redes que aprenderían solas es el que mostraste en la filmina 21 o es otro modelo? No, no, no. Es otro modelo. Es más, tienen inclusive múltiples partes. O sea, básicamente, así lo tiro rápido nomás, pero lo que están intentando es generar un modelo interno que pueda modelar a sí mismo y modelar el ambiente y entender cómo se dan las interacciones de todo lo que pasa entre el ambiente y cómo interactúa él con el ambiente y aprender esas cosas. Entonces, se parece más a lo que tendría a ser como una conciencia, si se quiere, entre comillas. Pero bueno, estamos lejos todavía de eso. Bueno, simplemente para cerrar esta sección, traigo acá a nuestro querido Alan Turing que planteó la pregunta de ¿cuándo nos daremos cuenta de que una máquina está pensando? Y para escaparse un poco de la trampa de las definiciones, planteó su Imitation Game, básicamente ese test de Turing, que dice que si yo hablo a través de una interfaz que no sé si de atrás hay una máquina o una persona y no logro distinguir si de lo que hay de otro lado es una persona o una máquina, puedo asegurar que la máquina, si es una máquina que está del otro lado, está pensando. Bueno, eso yo me atrevo a decir que hoy con los últimos algoritmos, como por ejemplo el ChatGPT, ya lo hemos conseguido. Pero bueno, después hay argumentaciones varias y además la vara cada vez la estamos subiendo más. Y eso está muy bien, pero bueno, mucho debate. Y otra reflexión es que estamos viendo que la inteligencia artificial cada vez está más cerca de pensar como nosotros, pero eso también nos lleva a ver que nuestra forma de pensar también está un poco más cerca de lo que son procesamientos, algoritmos y demás. Con lo cual, bueno, eso también lleva a múltiples reflexiones. Bueno, segunda parte.