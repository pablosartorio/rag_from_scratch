 Gracias a todos. Gracias por sumarse. La charla de JAPS GPT. Podemos seguir hablando un poquito de esta herramienta que si veis ya hubo una charla anterior. Me pareció que bueno seguir conociéndola. Y bueno, después de cualquier cosa al final hacemos una tanda de preguntas. Igualmente me pueden ir interrumpir y vamos viendo. Yo no voy a estar viendo el chat así muy constantemente, así que cualquier cosa hable por micrófono. Si me entero, si hay alguna duda o algo. Bueno, me presento. Mi nombre es Fernando Pagano. Soy Account Architect. Estoy trabajando con el equipo de Ariel y Susanne en la cuenta de Tenaris. Tenemos varios proyectos en el net core con Azure. Así que bueno. El equipo está con esas tecnologías. Hace casi 14 años que estoy en BAUFES. Y bueno, pasé por varias tecnologías en todo ese tiempo. La agenda que tenemos para hoy es una introducción. A la herramienta. Vamos a ver una técnica. Esta propuesta en un artículo. Después vamos a hacer un repaso de lo que vimos. Una charla abierta y encierre. Introducción. Bueno, no puede faltar el meme. No sé si son las virtudes de las redes sociales, pero es muy típico. Que aparezca algo que diga bueno, acá está lo último que tenés de chat GPT con esto. Vas a hacer plata o lo que sea. Así que espero que esta no sea una charla así. Si no, soy el que le están apuntando. Bueno. Bueno. Que está GPT? Bueno. Es una inteligencia artificial. Es una red neuronal. Es la tipo Large Language Model. Que digamos, están entrenadas para los temas de textos. Para comprender y generar textos. Es una red que usa una arquitectura de tipo Transformer. Que es diferente a la recurrent network. Transformer lo que hacen es generar tokens a partir de los. Cada contenido que tiene cada palabra. Y hace una interrelación entre cada. Cada contenido. Cada palabra. Para determinar un poco mejor el contexto que las recurrentes. Que lo hacen un poco más secuencial. Y recursivo. Entonces, los Transformers se vio que era mejor hacer una interrelación entre todos. Valorar los pesos y ver cuál era la mejor respuesta. Esto está basado en un paper que se llama Attention is all you need. Al final está el link para que me quede leer. Que es del 2017. Ahí como notación. El sujeto GPT tiene 175.000 millones de parámetros. Y es la versión 3. La versión 4 todavía que lo superó tiene más. Entonces, la cantidad de procesamiento que tiene. Y la cantidad de aprendizaje que tiene. Es muy grande. Bueno, vamos a repasar un poco lo que. Lo que dijo Alejandro Gómez. Él en su charla. Dio algunos. Algunos puntos que eran ayudar a resolver problemas de codificación. Generar generación de código. Y buscar hacer línea. Acá también está el link de la charla. Por si lo quieren. Revisar y ver de vuelta. Está bueno la charla. Hace una introducción más larga. Todo lo que es. Yo estoy haciendo más que nada. Voy a hacer más. La parte del uso. Y de una práctica en particular que está propuesta. El artículo que le mencionaba. El artículo de este que vamos a ver. Está un poco más relacionado a la generación de código. Pero bueno, vamos a explotarlo. Y ver. Que cosas nos. Nos da como para utilizar. Antes me gustaría lanzar una encuesta. Vamos a ver si me sale. Les dije que llegar al. Al teams. Avisan si llego por favor. Sí. Sí. Sí. Llegó. Gracias. Avisan si llego por favor. Sí. Sí. Sí. Sí. Sí. Sí. Sí. Sí. Sí. Sí. Sí. Sí. Sí. También y squared. Y cpc J23 slightly. Llegó. TListen. John. Ditzi. Y not bag checkpoint. Not bag el отдел. Porque changer. Dos. No digan. ¡ generosity we are! Not bag check S rarely afterwards. La de Joabiert y dos las cuesta, pero más o menos para que tengan una idea, están 45% gente que usó chapetella para programación, otras que lo usaron para otro tema y un 21 que hasta ahora no lo había usado, pero bueno, está como variado, pero bastante gente, ya casi la mitad, usó para temas de programación, eso es importante. Bueno, ahora vamos a ir a la técnica en sí que les mencionaba. Esta técnica es un artículo que se publicó Martin Fowler, que es algo que está propuesto por su jao, no sé si se pronuncia así, pero bueno, es la persona que está en el artículo, pero lo pronunciado bien. El nombre del artículo es un example of LMPrompting for Programming. Bueno, si lo leyeron, quizás esto los ayude a hacer un sum up de ese artículo y podamos también hacer algún debate. Y si no, bienvenidos también para ver cosas nuevas sobre técnicas de utilización de estas inteligencias artificiales. Lo primero que vamos a hacer es decirle a la inteligencia artificial que queremos que se le provea la inteligencia artificial, en general se le llama LMPrompting. Entonces, este LMPrompting, esta es la primer parte del LMPrompting, entraba toda una diaponte, entonces está dividida en dos. Lo primero que hace mención es al stack tecnológico. Entonces, cuando le decimos lo que queremos construir, primero le decimos, bueno, vamos a construir un sistema, yo en este caso elegí que el sistema sea el cálculo de las secuencias Fibonacci para que sea algo sencillo. En el artículo hay algo un poco más complicado que está bueno también para leer, pero quizás para una charla se hacía un poco extenso para explicar. Tenía React, capaz que no todos son de React, son otras tecnologías, también estos network, pero es algo mucho más sencillo y igual no nos vamos a detener mucho en el lenguaje de programación, sino en lo que le vamos a pedir al chat. Entonces, lo primero que se le dice, bueno, es ir a este stack tecnológico, Angular, Netcore, y el test en Netcore. Y le voy a decir que el código, quiero que lo escriba en ese stack, quizás uno puede decir que tiene ese stack tecnológico, pero la chat puede estar interpretando otra cosa, entonces por la duda se lo reforzamos. Y le vamos a decir después una estrategia de implementación en puntos. Vamos a puntear una estrategia de implementación. Y va a ser bueno, se va a utilizar Netcore como backend, el formato API, con unit test para métodos de controller, que hay una utilización de controller, y Angular se utilizará como frontend. Esto es algo muy sencillo, obviamente esto se puede hacer con una lista bastante más amplia. Quiero visualizar acá más o menos cuál es el prompt que estamos buscando. Ahora dijimos, stack tecnológico y una estrategia de implementación con una guía de instrucciones en paso. Eso se conoce como instruction prompting y chain of thoughts. Estas dos cosas serían el punteado y la cadena de pensamiento, sería la traducción o algo así. Es como encadenar lo que uno quiere hacer para que no haya ambiguidades o minimizar las ambiguidades de lo que uno le está pidiendo a ese chat. Debido a eso, le voy a pedir algunas cosas más, por ejemplo usar los siguientes patterns, la pido utilizar formato res, y le voy a declarar el requerimiento. El requerimiento va a ser crear una vista en Angular que reciba un número per input llamada la API donde se calcula el número Fibonacci, teniendo en cuenta el número ingresado y la posición dentro de la secuencia Fibonacci. Pido el número 10 perteneciendo a la secuencia y lo tiene a calcular. Y lo que voy a decirle acá, que es importante, proporciona una solución siguiendo la guía mencionada anteriormente, todo lo que dijimos antes, pero lo voy a decir que no genere el código todavía. Esto es algo importante de tener en cuenta. Y le voy a decir que describa una solución, pero que la haga tipo guía en puntos y que con eso me genere algo que lo vamos a llamar master plan. Para así cada vez que necesitamos referirnos a la solución la llamamos como master plan. A eso se le llama generating knowledge. Eso sería, como digamos, la interacción, la primera interacción que tuvimos con el chat, que nos deje un plan de trabajo. Y a eso se le llama de esa forma. Esto es un recordatorio de ingresar información accesible. Si dieron, por ejemplo, que hice no puse nada comprometedor, entonces se lo usan en el trabajo. Tienen en cuenta eso. Entonces siguiendo con el esquema de cómo viene el flow, hasta ahora le pasamos el prom, entonces esperamos que nos de un plan. El plan y la solución, como le dijimos, como se lo pedimos al chat, es un punteo. Entonces todavía no tiene código. Si está perfecto, pues es lo que yo le pedí. Entonces me dice acá, bueno, voy a crear una configuración inicial del proyecto, uno en Angular utilizando Angular Click, otro en plan con Netcore. Me está diciendo las cosas que va a hacer el backend y las cosas que va a hacer el frontend. Yo tengo aquí la solución entera del plan. No la voy a meter, no la puse también en el PPT, pero esto acá son 1, 2, 3, 4, 5, 6 puntos. Entonces estos 6 puntos son los que vamos a llamar como el master plan. Y acá me dice, no, recuerda que esto es solo un plan general y los pasos pueden variar. Entonces a partir de ese plan, como yo todavía no tengo código, tengo la posibilidad de decir, bueno, sabes que hay algo acá que quiero cambiar. Es un momento oportuno para introducir cambios y no tener que estar, si ya tenía el código, reescribiendo todo el código. Entonces le voy a pedir en el punto 4 del master plan, podemos agregar un loading en la pantalla, un tipo de, como una espera, como que está haciendo algo. Pues acá en el 4, estoy señalando con el 4, el punto 4. Como es eso. Ok, entonces por supuesto, ahí si algo está bueno es que siempre te responde muy bien, te tratas muy bien. Así que por supuesto, siempre hay que decirle gracias porque por las dudas no se sabe qué va a pasar en el futuro con la I, yo siempre les pongo gracias. Disculpame, te molesto con esta pregunta, por la duda la trato bien. Bueno, así que me da la propuesta de cambiar el punto 4. Bueno, me dice algunos detalles también, me dice que voy a agregar la base de isLoading, que dice isLoading, cuando está cargando va a estar en true, va a estar en false, cuando se termina de cargar, quiero usar el NGXLoading para ese estado. Así que esto es como muy importante porque nos da una posibilidad de jugar con nuestra definición y ir poniéndole cosas antes de tener todo el código resuelto. Creo que es uno de los puntos más fuertes que tiene el artículo, es la ida y vuelta que podemos hacer en este punto. Entonces ahora le pedí que vuelva a escribir el plan y que además le agregué los nombres de los componentes, los métodos, algunas cosas, pero todavía le voy a decir sin incluir el código, como para que no meterme mucho en el código. Pues acá lo vemos completo. Y el último, esto. Aquí tiene eso, entonces bueno, me dice que va a construir, cambió las cosas, le puso los nombres, voy a poner un F1HController, F1HComponent. Entonces ya desde esta parte, ya también puedo interactuar y decirle, sabes que en vez de este controller o este componente vamos a llamarlo así o vamos a dividirlo en dos o vamos a cambiarle cosas y por ahora estamos hablando de definiciones y no todavía de código. Es como una de las partes más potentes de este approach. Bueno, en la sección se rompió la matrix. Esto ahora vuelvo al ejemplo que veníamos armando, lo quiero hacer un parate y contar una anécdota que me pasó usando la herramienta, como para que no confiemos 100% en lo que nos devuelve. Tenía una tabla con muchísimos campos, yo acá solo dejé uno como para tenerlo de referencia. Lo que yo quería hacer es que me diga un listado de columnas non-null y por alguna razón esta offset no aparecía en ese listado. Entonces yo le pregunté, offset es nuliable? Sí, la columna offset es nuliable, me pone. En la PPT anterior que decía non-null, así como que hay algo que no estaba funcionando muy bien. Lo que hice fue cambiar la estrategia de pregunta y pregunté de una forma diferente. Le puse la columna offset, puede ser nul? Me pone mis disculpas por la confusión anterior. La columna del ejemplo tiene la restricción non-null, ok, ahí se arregló aparentemente. Entonces le pregunté de vuelta por las dudas, a ver si ya se habría corregido. Y le pregunté con la pregunta original y me dice de vuelta lo mismo, que es nuliable cuando es non-null. Y como quería ver qué pasaba, seguía preguntando, hice de vuelta la misma pregunta y ahora me fue a non-null. Así que bueno, es un caso que la verdad que no seguí explorándolo, le hice algunas preguntas más pero seguía como medio con respuestas confusas. Entonces es como para tenerlos en cuenta cuando uno tiene una respuesta de charlotte que no siempre puede ser precisa. Y bueno, ahora como paso final le pedí que haga un poco de código. Entonces para no tener una chorradera de código le dije, bueno, puede generar el punto 2 nada más y esto es otra de las cosas que está bueno de tener un masterplan. Que me permite enfocarme en algunos puntos diferentes del plan, no ir a hacer todo, todo junto y decirle al interés de decirle que bueno, hacemos un sistema que haga todo esto y después perderse en los diferentes puntos que tiene ese sistema y que además, digamos, si uno tiene que cambiar algo, hacer interacciones o ir challengeando ciertas partes de ese sistema, no lo puede hacer. Entonces esta escambiatización, esta arquitectura, esta práctica, permite seguir de vuelta y un poco más de control sobre cómo le pedimos las cosas al chat. Entonces el código, acá le pedí el tema del backend, voy a ir de vuelta, acá que lo ven más completo. Bueno, el punto 2, el masterplan, lo habló a nada. Entonces me hizo un controller. Si yo reviso el código, no lo puse a ejecutar sinceramente, pero tiene lógica lo que hace y yo creería que se puede mejorar un poquito, pero no está mal, no está mal lo que hizo y bueno, una de las cosas que podemos hacer es eso, decirle, bueno, es que esto que hiciste acá, dame otra versión. Me hizo el test. Y bueno, esto me dice que ajuste la estructura, las membranes que corresponden. Una cosa que capaz que hay que ajustar de lo que mismo está devolviendo. Para el lado del frontend también, veis que gire el punto 3 del masterplan. Me hizo el código en angular, muy bien, me parece que está lógico. Hizo el componente, hizo la HTML y hasta me explica lo que está haciendo. Y me dice, bueno, acotártelo y emplazará el API endpoint con lo que corresponda al URL. Y también. La, digamos, el core de lo que quiero mostrar en esta presentación no es tanto el código que genera, sino la técnica de cómo se piden las cosas al chat, que llaman técnicas de prompting. Es decir, los buscan a ver tres millones, esta es una como para dar una introducción. Bueno, y para hacer un repaso de lo que vimos. Lo que lo que hicimos fue primero tener un contexto. De instrucciones, esas técnicas se llaman instrucción prompting y chain offset prompting. Eso genera un generated knowledge, que básicamente es el plan. Y ese plan lo que vamos a hacer es revisarlo, hacerle cambios, hacerle ajustes. Y ser unida y vuelta entre estos dos pasos, entre plan y instrucciones. Hasta tener algo que nos convence. Una vez que tenemos eso. Le vamos a pedir el código y de vuelta esto lo que tiene de bueno es que siempre puedo tener el plan y ir atrás y no tener que hacer cosas. Vamos después a hacer parches sobre el código, entonces puedo empezar de cero y puedo hacer un proceso repetible. Incluso lo que puedo hacer es tener todo esto en una API. Yo podría hacer que los prompts sean los payload del API y ir llamando a las diferentes veces y ver las interacciones como las puedo automatizar. Bueno, ¿cuáles son las ventajas? Que es un poco lo que venimos hablando. Primero es visualizar el masterplan. Eso es como la primera ventaja que uno puede ver ahí. Puedes ir al chat que le muestre los pasos sin ir tanto al detalle del código y eso nos da una visualización. Una visualización y nos podemos imaginar lo que queremos y es eso o si tenemos que seguir afinando el prompt. Usar una estrategia del chain of sort que eso es lo que nos permite. Esta chain of sort está mezclada con las con la extraction. Nosotros le pusimos el punteado, le pusimos 1, 2, 3, 4. Eso es importante. Por que genera ayuda a cómo el chat genera la respuesta. Sin esas cosas que le hace el contexto se pierde un poco y se hace un poco más no determinístico. Si bien es no determinístico, nosotros le dejamos más libre el prompt. Y puede generar eso. Las evoluciones no van a ser las mismas. En esto le encadenamos los pensamientos y de alguna forma estamos forzando ciertas respuestas. Después lo otro que es muy interesante es que esto va a hacer interacciones. Ir y venir y ir cambiando cosas. Entonces ahí podemos ver un problema que tengamos. Volver atrás a solucionarlo o agregarle cosas, volver atrás a solucionarlo. Después otro ventaja es que esto divide el problema. Y lo que tiene de bueno esto es que estos procesos necesitan como mucho proceso y mucha memoria. Entonces lo que puede llegar a pasar es que si yo hice una cadena muy larga y no hice el punteado y no hice un plan. Puede llegar a pasar que pierda el contexto y no me responda o me responda otra cosa. Puede pasar que directamente me de un error, que ya no le de más el procesamiento. O puede pasar que me de cosas equivocadas. O puede pasar que me de cosas equivocadas. Entonces es muy importante esto de dividir de esta forma en instrucciones y ir haciendo el mapa, el plan. Y ir haciendo como de apartes. Esto con dividir y evitar errores está encadenado. Esto evita errores. Si yo divido voy a evitar esto que vigiante. Que ya ha mucho tiempo de proceso o que directamente se desperta el contexto o que directamente un error y no tengamos respuesta. Entonces eso es un poco parecido a dividir. Y poder iniciar nuevamente, que esto me parece fantástico. Uno tiene el prompt y de ahí empieza de vuelta si algo sale mal. Entonces no perdés tantas cosas. O mejor dicho no te mareas si hiciste un prompt que no estaba muy bien guiado. Si no estaba muy bien guiado vas a tener que ir y venir y ir atrapando cosas a medio adivinando. Por ejemplo si está bien esquematizado con instrucciones y chendo sort es un poco más fácil. Y después lo que mencioné antes también esto es que puede usar APIs. Es mucho mejor. Porque hasta puedo pensar en cómo automatizarlo el esquema. Bueno, ahora les voy a dejar otra encuesta. Ah. Con eso ya vimos el contenido de la charla, pero me gustaría re-preguntar. Ahí bueno, es similar a la que estábamos a la pregunta inicial. Pero ahora viendo un poco lo que comentamos en la charla. Si digamos les dio alguna curiosidad. Lo van a probar, no le van a probar, no les interesa. Ahí tengo un 4% que no lo va a aplicar, no le convenció para nada. Vamos a tener que armar otra charla a ver si los convence a mí. No sé si les convence a mí. Si les convence a mí, no les convence a mí. Y ahora vamos a ver si les convence a mí. No les convenció para nada. Vamos a tener que armar otra charla a ver si los convence a mí. A ver si le deja abierto. Pueden seguir votando si quieren. Bueno, ahora si tienen alguna pregunta. Yo por último, también lo que tengo es esta comparación que hizo una persona que habla mucho de inteligencia artificial en las redes. Se llama Carlos Santana, es dotCBC en las redes sociales. Él comparó VAR contra ChopGPT 4. Bueno, pareciera interesante porque era como medio un referente de todas lo que es estas tecnologías. Y bueno, él encuentra que los inteligencia skills de ChopGPT siguen siendo un poquito más buenos que los de VAR. Pero bueno, esto evoluciona siempre. Así que seguramente se va a poner en línea VAR y va a estar parecido a ChopGPT. También lo otro para tener en cuenta es que VAR está en algunos idiomas. ChopGPT es multilinguaje. No lo comenté, pero todo lo que hice lo hice en español. Casi puse muy pocas palabras en inglés. Así que eso también es un punto de flexibilidad de la herramienta que cualquiera puede usar. No sé si alguno quiere hacer alguna pregunta. Yo tengo una pregunta que anda dando vueltas por ahí últimamente con todo esto de ChopGPT y de VAR. ¿Vos considerás que todo esto puede tener impacto en la cantidad de puestos de trabajo de desarrolladores y demás? Yo también me voy a preguntar. No, la verdad que no tengo una respuesta. Mi intuición es que la gente que tiene una pregunta, que es la gente que tiene una pregunta, que es la gente que tiene una pregunta, la verdad que no tengo una respuesta. Mi intuición es que esto va a ser un acelerador. Pero es mi intuición nada más. ¿Por qué me metí a ver un poco la tecnología y cómo viene? Porque me parece que si vos empezás a hacer un sistema con esta herramienta y si lo empiezas a hacer de cero, si lo empiezas a hacer con esta herramienta, me parece que va a tener más ventajas. Esta y cualquier otra similar, ¿no? Con Pilot, que sea de que nos ayude al día a día de desarrollo. Ok, gracias. Ahí Alejandro tiene la mano levantada primero. ¿Cómo estás Fernando? Buenas tardes. Bueno, muchísimas gracias por la presentación. La verdad, este concepto de técnica de prompt yo lo uso, ya te lo expliqué, pero como preguntas y respuestas, ¿no? Sencillamente lo uso como un buscador más rápido e inteligente. Mi pregunta era, digamos, ¿olvidar? Olvidándonos por un momento de que si es chat, Gps, si es, no sé, la próxima herramienta, que algo mejor que el concepto de inteligencia artificial o lo que sea, no sé si conocés el concepto de hype cycle, ciclo de euforia. Es como una curva, hay una consultora que se llama Garner en Haití, y hay una curva, entonces, sitúa herramientas en esa curva. Entonces, al principio hay como un pico de expectativas, y después se alcanza una meseta menor al pico, en el que ya se sabe cuál es la capacidad real de esta herramienta y si sirve o no. Yo te quería preguntar vos, a partir de tu experiencia, no sé si esto es parte de tu trabajo diario, usar chat gbt para desarrollar, ¿cómo lo ubicas? Digamos, si para vos está madura para tu trabajo, tal como es tu trabajo hoy en día, o todavía no. Es una buena pregunta. No tengo una respuesta más ólida, te voy a dar mi impresión. Yo la uso, no la estoy usando diariamente, sí la uso como algunas consultas de desarrollo puntuales, y sí me gustaría usarla cada vez más. Entonces, un poco la intención de armar esta charla fue ver un poco qué había. Y hay mucho más de esto, ¿no? O sea, hay cursos de prompting que se pueden hacer, o lo cual me parece que es algo que sí tiene un hype, si querés, pero va a ser una herramienta que la vamos a usar. No sé si así como está ahora, o si más integrada a la SIDE de los desarrollos, como Pile o Tiesas, pero me parece que sí la vamos a utilizar. Es una apreciación y no tengo digamos una estadística. Estaría bueno tener algún artículo como para bajarlo. Es para la próxima charla si quiere tener. Hay más manos, ¿no? Nicolás, creo. Y todo, creo que yo estaba como número uno, gracias Fer, por la charla. Primero, alguna reflexión por lo que decían antes. A ver, con lo de reemplazar puestos de trabajo y eso. Yo creo que esto es una herramienta más que se va a incorporar. Y digo, o al menos como viene la mano, no parece ser que se pueda prescindir de un desarrollador. En todo caso, es una herramienta más que el desarrollador va a tener que aprender, como en su momento pasaron, no sé, de Assembler a lenguajes de más alto nivel o como aparecieron las Sides con IntelliSense y cosas. Y hoy ya no había que ir más al manual y digo cualquiera de esas revoluciones que digo, de alguna forma mejoran la productividad y ayudan. Pero a su vez, como eso mejora, también la complejidad de los desarrollos que hay que hacer también son más complejos, con lo cual no deja de ser una carrera que siempre va a ir más o menos pareja. Pero sí es importante que no nos quedemos atrás en esa carrera y que no nos perdamos las ventajas porque otros sí las van a aprovechar. Con respecto a eso de aprovechar las ventajas y eso, mi consulta iba más por el lado de, hay bastante controversia últimamente de este código generado que tan legal es usarlo en nuevos desarrollos, teniendo en cuenta que esto está entrenado con código de otra gente que tiene licencias probablemente no compatibles con lo que uno está haciendo o esas cosas. ¿Eso leíste algo, viste algo sobre ese tema en particular? Leí sobre más genérico, no tanto en el código, porque también con el arte hay un tema, ¿no? Por lo que sea música, hasta dónde es legal. La verdad es que no sé algo concreto. Sé que puede haber alguna marca que se pueda llegar a ser, pero eso va a depender de que las empresas que hacen esta tecnología se pongan de acuerdo, no las que hacen esta tecnología. Digamos que las empresas que hacen esta tecnología se pongan de acuerdo, no las que hacen estas tecnologías. En cuanto al código, un poco más difícil ponerle una marca, más no sé, capaz que un encabezado o alguna cosa así, que esté avisando de que esto tiene algún copyright. Pero no, todavía no leí nada de que haya una judicialización del tema. No escuché que haya eso. Sí, vi que hay personas que están atentas a que, ojo, que esto puede tener un impacto si estás usando algo que tiene copyright. Sí, también está el otro lado, que es las cosas que uno sube a Chatchip IT. Chatchip IT las usa para entrenar nuevas cosas. Entonces, sí, digo, cuando generás algo nuevo no está ese problema, pero si vos querés ver un error en tu código y le querés preguntar sobre el error en tu código, tengamos cuidado con el código de nuestros clientes que subimos acá, porque estamos exponiendo el código de los clientes. Ante la duda para usar estas herramientas, consulten los clientes donde están trabajando a ver si es válido o si no tienen ninguna objeción por las dudas. Pero bueno, y ahí les dejo por chat una comparativa de herramientas parecidas a estas que vi hoy que pueden servir también. Gracias, Fer. ¿Quién sigue? Nicolás, creo. Buenas, ¿qué tal? Fer, muy buena la charla y bueno, me llevo la técnica esa del Masterplan. Gracias. So, casi todos los días Chatchip IT, pero eso no lo estaba haciendo y suma muchísimo. Lo que te quería preguntar y de paso para saber, bueno, vos mencionaste dos cosas. Uno, el uso de la API. El problema de la API es que es paga. Bueno, la que no es paga se corta cuando uno lo usa como API y la que es paga por ahí puede llegar a hacer... al hacer muchas iteraciones en el desarrollo no siempre es una opción. El otro tema es que muchas veces uno necesita enseñarle cosas y bueno, lo que se mencionó recién, Guillermo, esto de que eso significa darle información que a veces uno no le puede dar. Y después lo otro que vos habías mencionado también es las otras herramientas como Copilot que por ahí están más integradas en un IDE de desarrollo. Entonces, en este panorama de alternativas que hay a ChatGPT, yo tengo entendido que ChatGPT es la que más avanzada está en la calidad de lo que genera. ¿Eso vos lo ves así o están de acuerdo o hay otras opciones que ya mencionaste justo Vard pero de las que están orientadas a código que puedan llegar a competir? Esa es una pregunta y la otra, por lo menos de lo que relevé, Liyama y las otras las que son de código abierto están muy lejos de ChatGPT. Pero la que quería explorar es esa que puse en el chat de código y quería saber si habían considerado estas alternativas y su madurez o cómo son en comparación con ChatGPT. StarCoder justo fue publicada hace unos 10 días, no me acuerdo, hace muy poco salió. Que supuestamente se acerca más a algo tipo el Codex o ChatGPT. Yo por ahora de la experiencia que vi, la de chat es la que como dijiste vos, está más precisa en generación de código. Pero bueno, habría que seguir investigando ahí también como para hacer una charla más de comparación. Bueno, gracias, era para ver si había. Estamos todos ahí en la misma entonces, viendo lo que sale. Gracias. Este muchacho que les mencioné de .cbc en general tiene como bastante probado el último que sale y cuando sale algo que va a generar impacto te lo anticipa y en general te da bastante. Quiero decir que sea el maestro de todo, pero bueno, si lo siguen las redes y lees un poco lo que pone, capaz que es un poco una guía para tener en cuenta. Hace poco había mencionado una nueva que iba salido, pero creo que está como una invitación, a él le había llegado la invitación, ahora no recuerdo el nombre, pero digamos que tenía una cantidad de token mayor y bueno, como que podía llegar a superarla, pero hay que esperar porque es algo nuevo. Yo creo que digamos a lo que es nuestro día a día me quedaría con lo más probado y lo que nos dé resultado. Y también un poco volviendo a lo que vimos de generación de código, hay que estarle arriba y mirando un poco, porque no siempre estás generando quizás el mejor código o es raro que tenga errores igual, pero por ejemplo yo detecté un error, como este del que detecté, entonces hay que estarlo un poco arriba a lo que generan estas herramientas. Gracias de nuevo. No, por favor. Ari. Sí, siguiendo ahí con un tema que Nicolás comentó brevemente, yo quería saber si habías tenido oportunidad de relevar temas de costos, licencias o qué implicaría para nosotros si queremos utilizarlo como una herramienta más de desarrollo, si usamos la versión gratuita, si eso nos puede poner en un lío con la plataforma, un lío legal me refiero, ¿no? La versión para… ¿Qué info tenés ahí? Sí, la versión paga es de 20 dólares, si no me equivoco. Y no sé la gratuita si tiene algún tema de uso en compañías, habría que revisarlo, no lo tengo a gran memoria eso. Pero bueno, la paga está en 20 dólares. Está bien, yo para entender, digamos que deberíamos considerar si estamos utilizándola como una extensión o como una herramienta más para nuestros equipos, más allá que uno la utilice en el ámbito personal, digamos en el modo free, si lo usamos para trabajar, ¿qué deberíamos hacer o qué no deberíamos hacer? Sí, cual. Sí, hoy creo que generar la práctica y la licencia de la versión gratuita, generar la práctica y alinear con esto de los costos, esa es lo primero que deberíamos hacer si queremos implementarnos en los proyectos, ¿no? Hoy creo que no hay, más allá de las charlas, una iniciativa de baufes de que los grupos se vuelquen a usar estas herramientas, pero la podemos… la podríamos investigar como una iniciativa. Sí, de hecho, hoy con el equipo revisábamos más temprano y estamos ahí bosquejando una iniciativa para VineGear24, justamente para abordar estos temas y bueno, iniciar con el pie derecho en el uso de la herramienta y entender qué pasa, porque ya sabemos que muchos de nosotros la estamos utilizando en el día a día y bueno, ver qué implica eso, ¿no? Tanto los temas que comentaban anteriormente Guillermo con el tema legal respecto a Ojo, no subamos código de nuestros clientes a la herramienta o al menos tengamos el OK Format de nuestros clientes que nos permite hacerlo hasta este tema. O sea, estamos generando código que luego va a una herramienta por la cual, digamos, en definitiva, vamos a hacer negocios, o nuestros clientes hacen negocios y bueno, tenemos que ver si la licencia gratuita abarca eso, ¿no? Son todos temas que todavía están bastante en puertas de ser trabajados, lo mismo que charlamos anteriormente sobre el tema de confidencialidad y copyright. Lo iremos descubriendo sobre la marcha, pero bueno, estemos atentos a las novedades que se vayan publicando. Ahí vi que mandaron un link al curso de OpenAI. En la app también al final están ese mismo curso y hay algunos otros links que serían interesantes. Sí, perdona más para sumar un poquito ahí de experiencia en he trabajado algo con chat GPT de código. La verdad, gracias por los proms. Igual comparto que no los había usado con proms y creo que esa estructura ayuda mucho y dándole un poco de fuerza a lo que decía Guillermo. Me ha pasado mucho que cuando genero código, muchas veces las librerías no son las correctas y todo el código que te generas en base a una librería a veces son librerías deprecadas o son inseguras. Entonces creo que el trabajo del desarrollador va a ser una buena investigación y el chat GPT va a ser un apoyo porque si veo que falta mucho ese tipo de validaciones, obviamente chat GPT no va a validar si la librería es la más segura o no. Bueno, no sé si lo haga, no se lo he preguntado, pero por ahora no. Entonces, si mis recomendaciones no se fíen tanto porque las librerías no son semi actualizadas. En mi caso me pasa con con C para temas de embed y con node mismo. Entonces, creo que es un punto a tener en cuenta cuando generen código por ahí todo en chat GPT. Sí, muy bueno el punto. Mismo en el artículo este de Martin Fowler, a la persona esta sujao le pasó que o sea como módulo de test le usó un componente que no era digamos nativo. Entonces tuvo que reformular y decirle bueno para este test, para los test no uses esto. Entonces ahí bueno, un masterplan nos sirve para hacer esa interacción y un poco también como dice Ille, de que se va a reemplazar a devs. Hay un montón de términos que por más que tengamos la interacción artificial, digamos el que le hace el prompting tiene que saber, tiene que haber estudiado, tiene que conocer lo que está pidiendo. Porque si no, digamos el enlatado final puede ser muy lindo, pero si no lo puedes mantener, no puedes hacer nada, como que no te va a servir mucho. Creo que hay una persona, ¿no? Tante, puede ser. Sí, bueno, justo ya comentaste algo del tema que iba a decir, pero más que todo, he hecho GPT o a generar las inteligencias artificiales. Más que reemplazar van a ser una gran ayuda. No sé si muchos de ustedes habrán visto la imagen del Papa usando ropa de marca y todo. Todo eso ha sido generado con un prompt de alguien que realmente sabía especificaciones de cámara, lentes, vistas. O sea, no solamente tú le tienes que mandar al, bueno, al inteligencia artificial que estás queriendo usar algo, digamos. Yo quiero, no sé, una imagen de tal cosa y te lo va a generar, sino esto requiere de la persona que aparte sepa de lo que va a requerir. Por el momento, bueno, que sea un reemplazo, por lo menos por ahora, ¿no? Y hay mucho hype sobre eso. O sea, es muy, muy, está muy verde todavía como para poder dar una respuesta, pero sí es una gran ayuda. Y también requiero un conocimiento previo de la persona, como también los precios que están contando de que sí está votando libertades de precariedad. Acuérdense que ChavGPT está solamente entrenado hasta datos del 2021, entonces dos años en TEC es una vida. Así que hay que tener mucho cuidado en eso y sobre todo, nada, o sea, siempre, o sea, siempre uno tiene que tener el conocimiento para poder validar lo que se está devolviendo. Excelente, sí, es así. Y mismo hay, además de tener conocimiento específico, también esas personas usan herramientas para generar buenos prompts. Hay herramientas para generar prompts. Bueno, esto es un hondillo cuando uno se empieza a meter en eso. Bueno, ahí dejé el link a la encuesta, que hacemos siempre. No hay más preguntas, si alguien más quiere comentar algo. En el final de la PBT están las referencias. Gracias por participar. Excelente charla. Muchas gracias.